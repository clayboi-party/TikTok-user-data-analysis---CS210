{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c3a26b-fb16-45d7-81b7-81b402f9950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Total videos watched': 11332,\n",
       "  'Total watch time (minutes)': 12028.533333333324,\n",
       "  'Watch sessions': 566,\n",
       "  'Average session length (minutes)': 21.251825677267373,\n",
       "  'Longest watch session (minutes)': 291.56666666666666,\n",
       "  'Earliest video watched': '2023-06-12 13:10:36',\n",
       "  'Last video watched': '2023-12-08 07:04:47',\n",
       "  'Most active weekday': 'Monday'},\n",
       " {'Total Comments': 110,\n",
       "  'Average Comment Length': 34.53636363636364,\n",
       "  'Most used emoji': 'ðŸ˜­',\n",
       "  'Most used emoji count': 6},\n",
       " {'Total likes': 6667,\n",
       "  'Day with most liked posts': '2021-05-14',\n",
       "  'Likes count on that day': 167,\n",
       "  'First liked video': 'https://www.tiktokv.com/share/video/6825672473003003141/'},\n",
       " {'Total shares': 94,\n",
       "  'Day with most shared posts': '2023-09-18',\n",
       "  'Shares count on that day': 5,\n",
       "  'First shared video': 'https://www.tiktokv.com/share/video/7242030089142078746/'},\n",
       " {'Total Lives viewed': 29,\n",
       "  'Earliest watched live': {'Date': '2023-01-04 04:33:02',\n",
       "   'Link': 'https://vm.tiktok.com/ZM6Yne4dM/'},\n",
       "  'Latest watched live': {'Date': '2023-09-28 13:59:43',\n",
       "   'Link': 'https://vm.tiktok.com/ZM6YtTFfH/'}},\n",
       " {'Times Logged In': 2169,\n",
       "  'Most Used Device Model': 'iPhone15,3',\n",
       "  'Most Used Network Type': 'Wi-Fi',\n",
       "  'Most Used Carrier': 'Turkcell'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import emoji\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# Load the JSON data from the uploaded file\n",
    "file_path = r'C:\\Users\\sarp2\\Desktop\\user_data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        tiktok_data = json.load(file)\n",
    "    message = \"JSON data loaded successfully.\"\n",
    "except Exception as e:\n",
    "    tiktok_data = None\n",
    "    message = f\"Error loading JSON data: {e}\"\n",
    "\n",
    "print(message)\n",
    "\n",
    "\n",
    "\n",
    "def analyze_watch_sessions(data):\n",
    "    # Extracting the \"VideoList\" from the data\n",
    "    video_history = data.get(\"Activity\", {}).get(\"Video Browsing History\", {}).get(\"VideoList\", [])\n",
    "    \n",
    "    # Total videos watched\n",
    "    total_videos_watched = len(video_history)\n",
    "\n",
    "    # Converting dates to datetime objects\n",
    "    watch_dates = [datetime.strptime(video[\"Date\"], \"%Y-%m-%d %H:%M:%S\") for video in video_history]\n",
    "\n",
    "    # Earliest and latest video watched\n",
    "    earliest_video = min(watch_dates).strftime(\"%Y-%m-%d %H:%M:%S\") if watch_dates else None\n",
    "    latest_video = max(watch_dates).strftime(\"%Y-%m-%d %H:%M:%S\") if watch_dates else None\n",
    "\n",
    "    # Determining session lengths and most active weekday\n",
    "    watch_dates.sort()\n",
    "    session_lengths = []\n",
    "    session_start = watch_dates[0]\n",
    "    for i in range(1, len(watch_dates)):\n",
    "        if (watch_dates[i] - watch_dates[i - 1]) > timedelta(hours=1):  # Assuming a new session starts after an hour gap\n",
    "            session_lengths.append((watch_dates[i - 1] - session_start).total_seconds() / 60)  # Convert to minutes\n",
    "            session_start = watch_dates[i]\n",
    "    session_lengths.append((watch_dates[-1] - session_start).total_seconds() / 60)  # Convert to minutes\n",
    "\n",
    "    # Total watch time in minutes\n",
    "    total_watch_time = sum(session_lengths)\n",
    "\n",
    "    # Average session length in minutes\n",
    "    avg_session_length = np.mean(session_lengths) if session_lengths else 0\n",
    "\n",
    "    # Longest watch session in minutes\n",
    "    longest_watch_session = max(session_lengths) if session_lengths else 0\n",
    "\n",
    "    # Most active weekday\n",
    "    weekdays = [d.strftime(\"%A\") for d in watch_dates]\n",
    "    most_active_weekday = max(set(weekdays), key=weekdays.count)\n",
    "\n",
    "    return {\n",
    "        \"Total videos watched\": total_videos_watched,\n",
    "        \"Total watch time (minutes)\": total_watch_time,\n",
    "        \"Watch sessions\": len(session_lengths),\n",
    "        \"Average session length (minutes)\": avg_session_length,\n",
    "        \"Longest watch session (minutes)\": longest_watch_session,\n",
    "        \"Earliest video watched\": earliest_video,\n",
    "        \"Last video watched\": latest_video,\n",
    "        \"Most active weekday\": most_active_weekday\n",
    "    }\n",
    "\n",
    "# To extract emojis\n",
    "def get_emojis(text):\n",
    "    # Regular expression to match all emojis\n",
    "    emoji_pattern = re.compile(\"[\" \n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.findall(text)\n",
    "\n",
    "def analyze_comments(data):\n",
    "    # Extracting the \"CommentsList\" from the data\n",
    "    comments_data = data.get(\"Comment\", {}).get(\"Comments\", {}).get(\"CommentsList\", [])\n",
    "    \n",
    "    # Total comments\n",
    "    total_comments = len(comments_data)\n",
    "\n",
    "    # Average comment length\n",
    "    avg_comment_length = sum(len(comment[\"Comment\"]) for comment in comments_data) / total_comments if comments_data else 0\n",
    "\n",
    "    # Most used emoji and its count\n",
    "    all_emojis = ''.join(emoji for comment in comments_data for emoji in get_emojis(comment[\"Comment\"]))\n",
    "    emoji_count = Counter(all_emojis)\n",
    "    most_used_emoji, most_used_emoji_count = emoji_count.most_common(1)[0] if emoji_count else (None, 0)\n",
    "\n",
    "    return {\n",
    "        \"Total Comments\": total_comments,\n",
    "        \"Average Comment Length\": avg_comment_length,\n",
    "        \"Most used emoji\": most_used_emoji,\n",
    "        \"Most used emoji count\": most_used_emoji_count\n",
    "    }\n",
    "\n",
    "def analyze_likes(data):\n",
    "    activity_data = data.get(\"Activity\", {})\n",
    "    liked_videos = activity_data.get(\"Like List\", {}).get(\"ItemFavoriteList\", [])\n",
    "    \n",
    "    # Total likes\n",
    "    total_likes = len(liked_videos)\n",
    "\n",
    "    # Day with most liked posts and the count\n",
    "    like_dates = [datetime.strptime(item[\"Date\"], \"%Y-%m-%d %H:%M:%S\").date() for item in liked_videos]\n",
    "    most_liked_day, most_liked_count = Counter(like_dates).most_common(1)[0] if like_dates else (None, 0)\n",
    "\n",
    "    # First liked video\n",
    "    first_liked_video = liked_videos[-1][\"Link\"] if liked_videos else None\n",
    "\n",
    "    return {\n",
    "        \"Total likes\": total_likes,\n",
    "        \"Day with most liked posts\": str(most_liked_day),\n",
    "        \"Likes count on that day\": most_liked_count,\n",
    "        \"First liked video\": first_liked_video\n",
    "    }\n",
    "\n",
    "def analyze_shares(data):\n",
    "    # Extracting the \"ShareHistoryList\" from the data\n",
    "    shared_videos = data.get(\"Activity\", {}).get(\"Share History\", {}).get(\"ShareHistoryList\", [])\n",
    "    \n",
    "    # Total shares\n",
    "    total_shares = len(shared_videos)\n",
    "\n",
    "    # Day with most shared posts and the count\n",
    "    share_dates = [datetime.strptime(item[\"Date\"], \"%Y-%m-%d %H:%M:%S\").date() for item in shared_videos]\n",
    "    most_shared_day, most_shared_count = Counter(share_dates).most_common(1)[0] if share_dates else (None, 0)\n",
    "\n",
    "    # First shared video\n",
    "    first_shared_video = shared_videos[-1][\"Link\"] if shared_videos else None\n",
    "\n",
    "    return {\n",
    "        \"Total shares\": total_shares,\n",
    "        \"Day with most shared posts\": str(most_shared_day),\n",
    "        \"Shares count on that day\": most_shared_count,\n",
    "        \"First shared video\": first_shared_video\n",
    "    }\n",
    "\n",
    "def analyze_live_streams(data):\n",
    "    # Adjusting to the structure where \"Tiktok Live\" is directly under the main data\n",
    "    tiktok_live_data = data.get(\"Tiktok Live\", {}).get(\"Watch Live History\", {}).get(\"WatchLiveMap\", {})\n",
    "    \n",
    "    # Total Lives viewed\n",
    "    total_lives_viewed = len(tiktok_live_data)\n",
    "\n",
    "    # Extracting individual watch times and links\n",
    "    watch_times = [datetime.strptime(live[\"WatchTime\"], \"%Y-%m-%d %H:%M:%S\") for live in tiktok_live_data.values()]\n",
    "    watch_links = [live[\"Link\"] for live in tiktok_live_data.values()]\n",
    "\n",
    "    # Sorting by watch time to get the earliest and latest\n",
    "    sorted_watch_times = sorted(watch_times)\n",
    "    earliest_watch_time = sorted_watch_times[0] if watch_times else None\n",
    "    latest_watch_time = sorted_watch_times[-1] if watch_times else None\n",
    "    earliest_watch_link = watch_links[watch_times.index(earliest_watch_time)] if earliest_watch_time else None\n",
    "    latest_watch_link = watch_links[watch_times.index(latest_watch_time)] if latest_watch_time else None\n",
    "\n",
    "    return {\n",
    "        \"Total Lives viewed\": total_lives_viewed,\n",
    "        \"Earliest watched live\": {\n",
    "            \"Date\": str(earliest_watch_time),\n",
    "            \"Link\": earliest_watch_link\n",
    "        },\n",
    "        \"Latest watched live\": {\n",
    "            \"Date\": str(latest_watch_time),\n",
    "            \"Link\": latest_watch_link\n",
    "        }\n",
    "    }\n",
    "\n",
    "def analyze_login_history(data):\n",
    "    # Extracting the \"LoginHistoryList\" from the data\n",
    "    login_history = data.get(\"Activity\", {}).get(\"Login History\", {}).get(\"LoginHistoryList\", [])\n",
    "    \n",
    "    # Total times logged in\n",
    "    total_logins = len(login_history)\n",
    "\n",
    "    # Most used device model\n",
    "    device_models = [login[\"DeviceModel\"] for login in login_history]\n",
    "    most_used_device_model = max(set(device_models), key=device_models.count) if device_models else None\n",
    "\n",
    "    # Most used network type\n",
    "    network_types = [login[\"NetworkType\"] for login in login_history]\n",
    "    most_used_network_type = max(set(network_types), key=network_types.count) if network_types else None\n",
    "\n",
    "    # Most used carrier\n",
    "    carriers = [login[\"Carrier\"] for login in login_history]\n",
    "    most_used_carrier = max(set(carriers), key=carriers.count) if carriers else None\n",
    "\n",
    "    return {\n",
    "        \"Times Logged In\": total_logins,\n",
    "        \"Most Used Device Model\": most_used_device_model,\n",
    "        \"Most Used Network Type\": most_used_network_type,\n",
    "        \"Most Used Carrier\": most_used_carrier\n",
    "    }\n",
    "\n",
    "# To use these functions\n",
    "watch_session_analysis = analyze_watch_sessions(tiktok_data)\n",
    "comments_analysis = analyze_comments(tiktok_data)\n",
    "likes_analysis = analyze_likes(tiktok_data)\n",
    "shares_analysis = analyze_shares(tiktok_data)\n",
    "live_streams_analysis = analyze_live_streams(tiktok_data)\n",
    "login_analysis = analyze_login_history(tiktok_data)\n",
    "\n",
    "# Displaying the results\n",
    "watch_session_analysis, comments_analysis, likes_analysis, shares_analysis, live_streams_analysis, login_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a197c64-b5b2-4b01-9e64-49ce017f518a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
